\documentclass[titlepage,12pt,a4paper]{article}

\usepackage[left=2cm,top=3cm,right=2cm,bottom=3cm,bindingoffset=0.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{commath}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{csquotes}
%\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{tabto}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{sidecap}
\usepackage{wrapfig}
\usepackage{parskip}

\usepackage{fancyhdr}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=C++,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\footnotesize,
  stepnumber=1,
  numbersep=5pt,
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}


\pagestyle{fancy}\lhead{A} \rhead{C}
\chead{{\large{\bf B}}}
\lfoot{}
\rfoot{\bf \thepage}
\cfoot{}

\setlength{\headheight}{15.2pt}
\pagestyle{fancy}
\fancyhf{}
\lhead{ \fancyplain{}{COMP3431: Robotic Software Architecture} }
\rfoot{ \fancyplain{}{\thepage} }


\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{3cm}
        
        \Huge
        \textbf{COMP3431\\}
        \title{}
        \vspace{0.5cm}
        \Huge
        \textbf{Robotic Software Architecture}
        
        \vspace{0.54cm}
        
        \Large
        Assignment 2: Report
        
        \vspace{5cm}

	\large
	Nathan ADLER\\
	Aneita YANG\\

	\vfill
        
        \Large
        November 9, 2015
        
    \end{center}
\end{titlepage}

\pagebreak
\tableofcontents

\pagebreak
\section{Introduction}
In this assignment, both the hardware and software aspects of robotics are explored. The overall objective was to create a robot that could drive autonomously in an outdoor environment, whilst avoiding any obstacles. A motorised wheelchair was the baseline from which the robot was constructed.

To achieve the objective, the robot is equipped with a GPS and compass (using an Android phone with ROS). A laser scanner is also attached to the front of the robot, gathering information about the robot's immediate surroundings.

\subsection{Modules}

\subsubsection{Hardware}


\subsubsection{Software}

On the software side, five/six(?????) nodes run in conjunction to operate the robot:

\verb|dest_sender| keeps track of the robot's remaining waypoints.

\verb|gps_drive| publishes the direction in which the robot needs to travel to reach its destination.

\verb|rtk_gps_pub| ...

\verb|laser_safe| publishes movement messages, either directly to the bot's destination, or to avoid an obstacle.

\verb|motordata_arduino_send| ...

\verb|sick_tim| ... (TODO: reference the github)

\pagebreak
\section{Hardware}
\begin{itemize}
	\item Dell Latitude E6400 notebook
	\item SICK TiM551 2D laser scanner
	\item DLink DSL 2750B N300 Modem Router
	\item Sony Xperia Z3 compact
	\item Arduino Mega 2560 R3
	\item Sabertooth 2X25 regenerative motor driver
	\item 2 x 12V lead acid battery
	\item 2 x electric wheelchair motor
\end{itemize}

\begin{figure}
	\includegraphics[scale=0.8]{figures/hardware_chart.png}
	\caption{Hardware map of UGV}
	\label{figure:hardware_chart}
\end{figure}

\pagebreak
\section{Software}

TODO: Generate rqt\_graph of nodes talking to each other

\subsection{Planner}
The planner module is responsible for keeping track of the robot's waypoints and informs the robot of its next destination. 

The \verb|dest_sender| node parses a file containing the GPS coordinates of waypoints and turns each latitude-longitude pair into a NavSatFix message. Each waypoint is stored in a list (as a NavSatFix message), with the head of the list being the robot's next destination. \verb|dest_sender| publishes this message to the \verb|/ugv_nav/waypoints| topic for other modules to subscribe to.

\verb|dest_sender| subscribes to the \verb|/ugv_nav/arrived| topic, which signals when the robot has reached its destination. Messages which are published to the \verb|/ugv_nav/arrived| topic trigger a callback which removes the current waypoint from the list (i.e. the head of the list). If the robot has not reached its final destination and the list is not empty, the robot's next destination is published.

\subsection{Localisation}
The localisation module is responsible for determining the direction in which the robot needs to travel to reach its goal. The robot. In order to determine this direction, the robot must be aware of its position in GPS coordinates, its bearing from true north and the GPS coordinates of its destination.

To obtain this information, the robot is equipped with an Android phone running the \verb|android_sensors_driver| app which publishes:

\begin{itemize}
	\item Camera images: \verb|sensor_msgs/CompressedImage| and \verb|sensor_msgs/Image|
	\item Fluid pressure data: \verb|sensor_msgs/FluidPressure|
	\item Illuminance data: \verb|sensor_msgs/Illuminance|
	\item Accelerometer: \verb|sensor_msgs/Imu|
	\item Magnetic field: \verb|sensor_msgs/MagneticField|
	\item GPS fixes: \verb|sensor_msgs/NavSatFix|
	\item Temperature data: \verb|sensor_msgs/Temperature| \\
\end{itemize}

For this assignment, the \verb|gps_drive| node performs these required calculations. In particular, the \verb|gps_drive| node subscribes to the Android device's GPS fixes and magnetic fields (published on the \verb|/phone1/android/fix| and \verb|/phone1/android/magnetic_field| topics respectively). The GPS coordinates of the robot's destination are published to the  \verb|/ugv_nav/waypoints| topic by the \verb|dest_sender| node, which \verb|gps_drive| also subscribes to.

Calculating the bearing of the destination from the robot is dependent on the GPS coordinates of both the robot and the destination.

\begin{align*}
	\Delta{latitude}   	&= 	\text{destination\_latitude} - \text{robot\_latitude} \\
	\Delta{longitude}	&= 	\text{destination\_longitude} - \text{robot\_longitude} \\
\end{align*}

Supposing the robot is facing True North, and if $\beta$ is the bearing of the destination from the robot then:
\begin{align*}
	\beta		&=	\tan^{-1}({\frac{\Delta{longitude}}{\Delta{latitude}}}),\\
\end{align*}
If $\theta$ is the angle the robot must turn to reach its destination, then $\theta = \beta$.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{bearings.png}
	\caption{\textbf{Calculation of the bearing of the destination from the robot, if the robot is facing true north.}}
\end{figure}


\pagebreak


In the cases where the robot is not facing true north, then:
\begin{align*}
	\theta	&=	(-\alpha) + \beta
\end{align*}
where:
\begin{align*}
	\beta		&=	\tan^{-1}({\frac{\Delta{longitude}}{\Delta{latitude}}})\\ \\
	\alpha	&=	\tan^{-1}(\frac{\Delta{x}}{\Delta{y}})
\end{align*}
and $\Delta{x}$ and $\Delta{y}$ are given from the Android device's magnetic field readings.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{bearingsOffset.png}
	\caption{\textbf{Calculation of the bearing of the destination from the robot where the robot is not facing true north. NOTE: In this example, $\alpha$ is positive and $\beta$ is negative.}}
\end{figure}




\text{As the ???th decimal place provides up to ??? precision:}

\begin{align*}
	\text{distance\_to\_destination}	&= 	111,000 * \sqrt{(\text{difference\_lat})^2 + (\text{difference\_long})^2}
\end{align*}

If the distance to the destination is less than 5 (i.e. the robot is within 5 metres of its destination), it is considered to have arrived at its destination. At this stage, the \verb|gps_drive| node will publish a message to the \verb|/ugv_nav/arrived| topic, signalling to the \verb|dest_sender| that the robot has reached its destination and that a new destination is required.




As the robot obtains GPS fixes frequently, it is sensitive to small changes to its position. The frequent updating of the robot's GPS fix results in abrupt movement changes as the robot attempts to face the bearing to its destination. In order to reduce the amount of sudden directional changes, rather than continually looking for the most direct path to its goal, the direction the robot decides to travel is biased towards a `smooth path'.


TODO: Explain straight line bias calculations 


Once these biases have been taken into consideration, the \verb|gps_drive| node publishes the most applicable bearing (as a std\_msgs::Float32 message) for the robot to travel. The waypoint traversal module then performs the applicable actions based on this bearing.

\subsection{Waypoint Traversal}
The waypoint traversal module is responsible for physically getting the robot to its destination. The \verb|gps_drive|, \verb|laser_safe| and \verb|motordata_arduino_send| nodes work in conjunction to achieve this goal.

\subsubsection{Obstacle Avoidance}
To detect any obstacles in the robot's path, a laser scanner is attached to the front of the robot.

Given a bearing to travel along, the \verb|laser_safe| node will take one of two courses of action. If there is no obstacle in front of the robot, the robot will drive in the direction it was instructed to by the \verb|gps_drive| node. If an obstacle is present, however, the robot's first priority is to avoid colliding with the obstacle. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.34]{laser.png}
	\caption{\textbf{Range of laser scanner.}}
\end{figure}

Note that for the purposes of this assignment, the robot is instructed to scan for obstacles within a 90\degree field-of-view. That is, obstacles further than 45\degree to the left or right of the centre of the robot are deemed as harmless and are ignored.

\textbf{First Iteration}

The first iteration of obstacle avoidance involves bringing the robot to a complete stop when an obstacle enters the view of the laser scanner. As the UGV's main task is to drive autonomously in outdoor environments, this method proves useful for moving obstacles (e.g. people) that may enter and exit the frame quickly. \\

\textbf{Second Iteration}

The second iteration of obstacle avoidance attempts to drive around obstacles as they enter the danger zone (i.e. 45\degree left and right of the centre of the robot). The robot does this by picking the closest `safe' spot to the left of the obstacle, if possible, and driving towards it. In cases where the obstacle cuts out of the left-hand side of the laser's frame, the closest `safe' spot to the right is chosen. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.17]{obstacle2.png}
	\caption{\textbf{Obstacle avoidance paths.}}
\end{figure}

Once the robot is clear of all obstacles, it resumes driving towards its destination. \\

\textbf{Final Iteration}

TODO!




\subsubsection{Motor Control}

TODO: motordata arduino send. 

\subsection{Open Source SICK TiM Driver}

\pagebreak
\section{Results}

\pagebreak
\section{Future Work and Improvements}

\pagebreak
\section{Appendix}


\subsection{sensor\_msgs/NavSatFix.msg}
\begin{lstlisting}[language=C++]
Header header

/* Satellite fix status information */
NavSatStatus status

/* Latitude [degrees]. Positive is north of equator; negative is south. */
float64 latitude

/* Longitude [degrees]. Positive is east of prime meridian; negative is west. */
float64 longitude

/*
Altitude [m]. Positive is above the WGS 84 ellipsoid
(quiet NaN if no altitude is available).
*/
float64 altitude

/*
Position covariance [m^2] defined relative to a tangential plane
through the reported position. The components are East, North, and
Up (ENU), in row-major order.
Beware: this coordinate system exhibits singularities at the poles.
*/
float64[9] position_covariance

/*
If the covariance of the fix is known, fill it in completely. If the
GPS receiver provides the variance of each measurement, put them
along the diagonal. If only Dilution of Precision is available,
estimate an approximate covariance from that.
*/
uint8 COVARIANCE_TYPE_UNKNOWN = 0
uint8 COVARIANCE_TYPE_APPROXIMATED = 1
uint8 COVARIANCE_TYPE_DIAGONAL_KNOWN = 2
uint8 COVARIANCE_TYPE_KNOWN = 3

uint8 position_covariance_type
\end{lstlisting}


\end{document}
